# 大数据分析第4次作业实验报告

<p align='center'>201250037 韩陈旭</p>

## 1. 对于分类算法`C4.5`的理解

`J48`分类器是`Weka`中对于`C4.5`决策树分类器的实现，它是基于`ID3`的分类算法，利用信息熵进行分类。

训练数据是一组形式为$S = \{s_{1},s_{2}····\}$的已经分类的样本。每个样本$s_{i}$都由一个p维向量$(x_{1,i},x_{2,i}···，x_{p,i})$组成，其中$x_{j}$代表样本的属性值或者特征，以及$s_{i}$所在的类别。

在树的每个节点上，`C4.5`选择数据的属性，将其样本集最有效地分割成富含一个或者另外一个类别地自己。分割的标准是归一化的信息增益(熵的差异)。选择具有最高归一化信息增益的属性来做决定。然后`C4.5`算法在较小的子列表上重复进行。

`C4.5`有几个基本情况:

- 当列表中所有的样本都属于同一个类别时，`C4.5`只为决策树创建一个叶子节点。
- 在没有一个特征提供任何信息增益时，`C4.5`使用该类的预期值在书上创建一个决策节点。
- 遇到了以前没有见过的类的实例，`C4.5`使用预期值在树的根上创建以一个决策节点。

## 2. 数据集的处理思路

### 2.1 预处理

首先对于数据集进行与处理了，这里使用了`ReplaceMissingValues`,`Standardize`和`Normalize`分别进行缺失值处理，标准化和规范化。

```java
public Instances preProcess(Instances data) {
        try {
            Filter replaceMissingValues = new ReplaceMissingValues();
            replaceMissingValues.setInputFormat(data);
            data = Filter.useFilter(data, replaceMissingValues);
            Filter standardize = new Standardize();
            standardize.setInputFormat(data);
            data = Filter.useFilter(data, standardize);
            Filter normalize = new Normalize();
            normalize.setInputFormat(data);
            data = Filter.useFilter(data, normalize);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return data;
    }
```

### 2.2 构建分类器

`J48`分类器是`Weka`中对于`C4.5`决策树分类器的实现，构建`J48`分类器。

```java
public Classifier buildClassifier(Instances data) {
        J48 j48 = new J48();
        try {
            j48.buildClassifier(data);
        } catch (Exception e) {
            e.printStackTrace();
        }
        return j48;
    }
```

### 2.3 训练模型与模型评估

对于原始数据集，按照`8:2`的比例划分训练集和测试集，之后使用训练集训练模型，使用测试集评估模型的准确率。在训练之前使用`setClassIndex`方法设置分类与预测的属性，评估模型时使用到了`Evaluation`类。

```java
Instances data = IOHelper.loadARFF(DATASET_PATH);
            // 这里一定要设置预测属性
            data.setClassIndex(data.numAttributes() - 1);
            // 分出测试集和训练集
            int trainSize = (int) Math.round(data.numInstances() * 0.8);
            int testSize = data.numInstances() - trainSize;
            data.randomize(new Debug.Random(1));
            // 预处理
            data = modelGenerator.preProcess(data);
            Instances trainData = new Instances(data, 0, trainSize);
            Instances testData = new Instances(data, trainSize, testSize);
            // 使用训练集训练模型
            J48 model = (J48) modelGenerator.buildClassifier(trainData);
            // 模型评估
            String eval = modelGenerator.evaluateModel(model, trainData, testData);
```

### 2.4 保存模型

对于训练出来的模型，保存成`bin`文件。

```java
public void saveModel(Classifier model, String savePath) {
        try {
            SerializationHelper.write(savePath, model);
        } catch (Exception e) {
            throw new RuntimeException(e);
        }
    }
```

## 2. 实验结果截图

![image-20221009150240855](https://bobbyhan-images.obs.cn-east-3.myhuaweicloud.com/mysql/image-20221009150240855.png)